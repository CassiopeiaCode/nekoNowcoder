# 给定一张 n 个结点 m 条边的简单无向图... - 题解

### 比赛与标签
> **比赛**: 未指定

> **标签**: 分块, 并查集, 图论

> **难度**: 未提供

## 题目大意喵~

主人你好呀，喵~ 这道题是关于一个带颜色的小小世界（一个无向图）的故事哦。

在这个世界里，有 $n$ 个地方（结点），和 $m$ 条连接它们的双向小路（边）。每个地方都有自己的颜色。

我们定义了一种特殊的“团”~ 两个地方 $a$ 和 $b$ 如果属于同一个团，那就意味着，可以从 $a$ 出发，只走和 $a$ 颜色相同的地方，就能到达 $b$ 呢。换句话说，一个“团”就是图里同一颜色结点组成的连通块啦！

接下来，会有 $q$ 次魔法操作。每一次，会指定一个地方 $x$ 和一种新颜色 $c$。施法后，$x$ 所在地的整个“团”里的所有地方，颜色都会被统一修改为 $c$。

我们的任务是，在每次魔法操作之后，都要马上告诉小蓝，现在整个世界里总共有多少个“团”呢？

简单总结一下就是：
- **输入**: 一个 $n$ 点 $m$ 边的无向图，每个点有初始颜色，以及 $q$ 次操作。
- **操作**: 将点 $x$ 所在的同色连通块整体染成新颜色 $c$。
- **输出**: 每次操作后，图中总的同色连通块（也就是“团”）的数量。

## 解题思路分析

喵哈哈，这道题看起来有点棘手，尤其是修改操作会影响一整个连通块，还可能导致连通块合并，感觉会很复杂呢！不过别怕，跟着我的猫爪印一步步来，我们肯定能解决它的说！

### 最初的想法：朴素的并查集

一看到“连通块”这个词，我的猫猫雷达就响了——这不就是并查集（DSU）的专长嘛！我们可以用并查集来维护这些“团”。

最开始，每个结点都是一个独立的团，所以总共有 $n$ 个团。然后，我们遍历所有的边 $(u, v)$，如果结点 $u$ 和 $v$ 的颜色相同，就把它们合并到同一个集合里，每合并一次，总团数就减一。

这样初始化之后，我们就得到了最初的团的数量。那么，当一次修改操作 `(x, c)` 发生时，会发生什么呢？

1.  首先，我们要找到 $x$ 所在的整个团。这可以通过找到 $x$ 在并查集里的根结点 `root_x` 来代表。
2.  这个团里所有结点的颜色，都从旧颜色 `old_c` 变成了新颜色 `c`。
3.  最关键的一步来了！这个团染上新色后，可能会和它周围原本就是颜色 `c` 的其他团连接起来。我们需要检查这个团的所有边界边，如果一条边的另一端连接着一个颜色为 `c` 的团，就要把它们合并！

这个思路是正确的，但是...效率怎么样呢？如果一个团非常大，比如有 $O(N)$ 个结点和 $O(M)$ 条边，那么每次修改我们都要遍历它所有的边界边，这太慢啦！$q$ 次操作下来，肯定会超时的说。呜...必须想个更快的办法！

### 优化！“轻重”之分的分块思想

既然大的团处理起来很麻烦，那我们能不能区别对待它们呢？这就是“分块”思想的魅力所在，喵~ 我们设定一个阈值 `BLOCK_SIZE`（比如 $\sqrt{N}$），然后把图中的团（连通块）分为两类：

*   **轻量团**：团里结点的邻居（所有成员的所有邻居）数量小于 `BLOCK_SIZE` 的。
*   **重量团**：团里结点的邻居数量大于等于 `BLOCK_SIZE` 的。

为什么是按邻居数量而不是成员数量呢？因为我们最关心的就是团的“边界”，也就是它和外界的连接。邻居数量直接反映了边界的复杂程度。

这样区分之后，我们就可以采用不同的策略啦：

*   **对于轻量团**：它们的邻居不多，就算每次都暴力遍历一遍所有邻居来检查合并，开销也不会太大。
*   **对于重量团**：它们的邻居太多，不能暴力处理。我们需要为它们建立一些“快速通道”——也就是更高效的数据结构，来快速找到特定颜色的邻居团。

### 核心数据结构与算法流程

好~接下来就是把这个想法变成代码的魔法时刻！

1.  **并查集 (DSU)**: 这是我们维护团的基础。我们需要 `parent` 数组和 `clique_count` 变量。
2.  **区分轻重**：
    *   `adj_light[i]`: 对于一个轻量团（根为 `i`），我们用一个 `vector` 来存储它所有的邻居结点。
    *   `heavy_component_id[i]`: 如果一个团（根为 `i`）是重量团，我们给它分配一个独一无二的ID，存在这里。如果 `heavy_component_id[i] == 0`，说明它是轻量团。
3.  **重量团的“快速通道”**:
    *   `heavy_adj_by_color[heavy_id][color]`: 这是为重量团准备的大杀器！它是一个 `map` 或者哈希表，对于ID为 `heavy_id` 的重量团，可以快速通过颜色 `color` 找到它所有邻居中颜色为 `color` 的那些团的根结点列表。
    *   `heavy_adj_to_heavy[heavy_id]`: 专门记录一个重量团和哪些其他的重量团有连接。这在处理重量团之间的合并时很有用。

**操作流程解析**:

**初始化**:
- DSU 初始化，每个点自成一派，`clique_count = n`。
- 读入所有边，但不立即处理。
- 读入初始颜色。
- 遍历所有边 `(u, v)`，如果 `color[u] == color[v]`，就合并 `u` 和 `v` 所在的团。

**处理一次查询 `(x, new_c)`**:
1.  找到 `x` 所在团的根 `root_x` 和旧颜色 `old_c`。如果颜色不变，直接结束，喵~
2.  **寻找合并目标**：我们需要找到 `root_x` 这个团的所有邻居里，颜色恰好是 `new_c` 的。
    *   如果 `root_x` 是**轻量团**：直接遍历它的邻居列表 `adj_light[root_x]`，找到所有颜色为 `new_c` 的邻居团，把它们记下来准备合并。
    *   如果 `root_x` 是**重量团**：利用它的快速通道！直接查询 `heavy_adj_by_color[heavy_id_x][new_c]`，就能瞬间得到所有需要合并的邻居团。同时，也要检查 `heavy_adj_to_heavy`，看看有没有需要合并的重量团邻居。
3.  **更新颜色和合并**：
    *   先把 `root_x` 团的颜色更新为 `new_c`。
    *   然后，将 `root_x` 和上一步找到的所有目标团一一合并。每次合并，`clique_count` 减一。
4.  **维护数据结构**：合并是整个算法最复杂的部分。
    *   **轻+轻合并**：合并它们的邻居列表。如果合并后新的团的邻居数量超过了 `BLOCK_SIZE`，就要把它“晋升”为重量团，为它建立重量团的那些数据结构。
    *   **轻+重合并**：总是把轻的合并到重的里面。遍历轻量团的邻居，更新重量团的邻居信息。
    *   **重+重合并**：把邻居列表规模较小的那个，合并到较大的那个里面。

这个过程听起来是不是像搭一个精密的积木城堡？虽然复杂，但每一步都井井有条，最终能高效地解决问题！

## 代码实现

这是本猫娘根据上面的思路，重新整理和编写的一份代码。我加了很多注释，希望能帮助你理解每一处的细节哦~

```cpp
#include <iostream>
#include <vector>
#include <numeric>
#include <algorithm>
#include <map>

using namespace std;

// --- 常量与全局变量定义 ---
const int N_MAX = 100005;
const int BLOCK_SIZE = 400; // 分块的阈值，通常取 sqrt(N) 附近

// 并查集相关
int parent[N_MAX];
int component_size[N_MAX]; // 这里存的是团的邻居数量，而非节点数

// 图和团的信息
vector<int> adj[N_MAX]; // 存储原图的邻接表
int component_color[N_MAX]; // 存储每个团的颜色（以根节点为代表）
int total_cliques; // 总团数

// --- 分块相关数据结构 ---
int heavy_component_id[N_MAX]; // 团的根 -> 重量团ID (0表示轻量团)
int next_heavy_id = 1;

// 重量团的邻居信息
map<int, vector<int>> heavy_adj_by_color[N_MAX / BLOCK_SIZE + 5]; // 重量团ID -> {颜色 -> [邻居团根]}
vector<int> heavy_adj_to_heavy[N_MAX / BLOCK_SIZE + 5]; // 重量团ID -> [邻居重量团根]

// 轻量团的邻居信息
vector<int> light_adj[N_MAX]; // 轻量团根 -> [邻居团根]

// 辅助工具
int visited_tag[N_MAX];
int current_tag = 0;

// --- 并查集基础操作 ---
int find_set(int v) {
    if (v == parent[v]) {
        return v;
    }
    return parent[v] = find_set(parent[v]);
}

// --- 核心逻辑函数 ---

// 将一个团升级为重量团
void promote_to_heavy(int root) {
    int new_id = next_heavy_id++;
    heavy_component_id[root] = new_id;

    // 整理邻居信息并存入重量团数据结构
    for (int neighbor_root : light_adj[root]) {
        if (heavy_component_id[neighbor_root] > 0) { // 如果邻居是重量团
            heavy_adj_to_heavy[new_id].push_back(neighbor_root);
            heavy_adj_to_heavy[heavy_component_id[neighbor_root]].push_back(root);
        } else { // 如果邻居是轻量团
            heavy_adj_by_color[new_id][component_color[neighbor_root]].push_back(neighbor_root);
        }
    }
    light_adj[root].clear(); // 清空旧的轻量团邻居列表
}

// 合并两个团
void unite_sets(int u, int v) {
    int root_u = find_set(u);
    int root_v = find_set(v);

    if (root_u == root_v) return;

    // 启发式合并：总是将小的合并到大的里面
    // 这里我们用邻居数量作为“大小”的评判标准
    if (component_size[root_u] < component_size[root_v]) swap(root_u, root_v);

    parent[root_v] = root_u;
    total_cliques--;

    bool u_is_heavy = heavy_component_id[root_u] > 0;
    bool v_is_heavy = heavy_component_id[root_v] > 0;

    if (!u_is_heavy && !v_is_heavy) { // 轻 + 轻
        light_adj[root_u].insert(light_adj[root_u].end(), light_adj[root_v].begin(), light_adj[root_v].end());
        light_adj[root_v].clear();
        
        // 去重
        sort(light_adj[root_u].begin(), light_adj[root_u].end());
        light_adj[root_u].erase(unique(light_adj[root_u].begin(), light_adj[root_u].end()), light_adj[root_u].end());
        
        component_size[root_u] = light_adj[root_u].size();

        if (component_size[root_u] > BLOCK_SIZE) {
            promote_to_heavy(root_u);
        }
    } else if (u_is_heavy && !v_is_heavy) { // 重 + 轻
        int id_u = heavy_component_id[root_u];
        for (int neighbor_root : light_adj[root_v]) {
            if (find_set(neighbor_root) == root_u) continue; // 已经是同一个团了
            if (heavy_component_id[neighbor_root] > 0) {
                 heavy_adj_to_heavy[id_u].push_back(neighbor_root);
                 heavy_adj_to_heavy[heavy_component_id[neighbor_root]].push_back(root_u);
            } else {
                 heavy_adj_by_color[id_u][component_color[neighbor_root]].push_back(neighbor_root);
            }
        }
    } else if (u_is_heavy && v_is_heavy) { // 重 + 重
        int id_u = heavy_component_id[root_u];
        int id_v = heavy_component_id[root_v];

        // 合并颜色邻居
        for (auto const& [color, neighbors] : heavy_adj_by_color[id_v]) {
            heavy_adj_by_color[id_u][color].insert(heavy_adj_by_color[id_u][color].end(), neighbors.begin(), neighbors.end());
        }
        // 合并重量团邻居
        for (int neighbor_heavy_root : heavy_adj_to_heavy[id_v]) {
            if(find_set(neighbor_heavy_root) == root_u) continue;
            heavy_adj_to_heavy[id_u].push_back(neighbor_heavy_root);
        }
    }
}

int main() {
    // 加速输入输出，喵~
    ios_base::sync_with_stdio(false);
    cin.tie(NULL);

    int n, m, q;
    cin >> n >> m >> q;

    // 初始化
    total_cliques = n;
    for (int i = 1; i <= n; ++i) {
        parent[i] = i;
        component_size[i] = 0;
    }

    for (int i = 1; i <= n; ++i) {
        cin >> component_color[i];
    }
    
    vector<pair<int, int>> edges;
    for (int i = 0; i < m; ++i) {
        int u, v;
        cin >> u >> v;
        adj[u].push_back(v);
        adj[v].push_back(u);
        edges.push_back({u, v});
    }

    // 初始同色团合并
    for (const auto& edge : edges) {
        int u = edge.first;
        int v = edge.second;
        if (component_color[u] == component_color[v]) {
            unite_sets(u, v);
        }
    }
    
    // 构建初始的邻居关系 (这一步在朴素解法中没有，是分块的核心)
    for(int i=1; i<=n; ++i){
        for(int neighbor : adj[i]){
            if(find_set(i) != find_set(neighbor)){
                light_adj[find_set(i)].push_back(find_set(neighbor));
            }
        }
    }
    for(int i=1; i<=n; ++i){
        if(parent[i] == i){ // 只处理根节点
            sort(light_adj[i].begin(), light_adj[i].end());
            light_adj[i].erase(unique(light_adj[i].begin(), light_adj[i].end()), light_adj[i].end());
            component_size[i] = light_adj[i].size();
            if(component_size[i] > BLOCK_SIZE){
                promote_to_heavy(i);
            }
        }
    }


    // 处理查询
    while (q--) {
        int x, c;
        cin >> x >> c;

        int root_x = find_set(x);
        int old_c = component_color[root_x];

        if (old_c == c) {
            cout << total_cliques << "\n";
            continue;
        }

        vector<int> neighbors_to_merge;
        current_tag++;

        // 寻找颜色为 c 的邻居团
        if (heavy_component_id[root_x] == 0) { // 轻量团
            for (int neighbor_root : light_adj[root_x]) {
                neighbor_root = find_set(neighbor_root);
                if (component_color[neighbor_root] == c && visited_tag[neighbor_root] != current_tag) {
                    neighbors_to_merge.push_back(neighbor_root);
                    visited_tag[neighbor_root] = current_tag;
                }
            }
        } else { // 重量团
            int id_x = heavy_component_id[root_x];
            // 从颜色哈希表中找
            if (heavy_adj_by_color[id_x].count(c)) {
                for (int neighbor_root : heavy_adj_by_color[id_x][c]) {
                    neighbor_root = find_set(neighbor_root);
                    if (visited_tag[neighbor_root] != current_tag) {
                        neighbors_to_merge.push_back(neighbor_root);
                        visited_tag[neighbor_root] = current_tag;
                    }
                }
            }
            // 从重量团邻居中找
            for (int neighbor_root : heavy_adj_to_heavy[id_x]) {
                 neighbor_root = find_set(neighbor_root);
                 if (component_color[neighbor_root] == c && visited_tag[neighbor_root] != current_tag){
                     neighbors_to_merge.push_back(neighbor_root);
                     visited_tag[neighbor_root] = current_tag;
                 }
            }
        }

        component_color[root_x] = c;

        for (int neighbor_root : neighbors_to_merge) {
            unite_sets(root_x, neighbor_root);
            root_x = find_set(root_x); // 根节点可能已改变
        }

        cout << total_cliques << "\n";
    }

    return 0;
}
```
**注意**: 上述代码是一个根据思路重构的教学版本，它简化了原AC代码中一些为了极致性能而设计的复杂部分（比如手动实现的链表哈希和`funq`去重技巧），并使用了`std::map`和`std::sort/unique`，这在逻辑上更清晰但在最坏情况下性能可能稍逊。原AC代码的精妙之处在于它对常数时间的极致优化。这份代码旨在帮助理解核心的分块思想和处理流程~

## 复杂度分析

*   **时间复杂度**: $O((m+q)\sqrt{N}\alpha(N))$，其中 $\alpha(N)$ 是并查集操作的极慢增长的反阿克曼函数，可以看作一个很小的常数。
    这是一个典型的分块算法的复杂度。简单来说，每次操作的开销主要来自两部分：对轻量团的操作和对重量团的操作。
    - 对轻量团的操作，由于其邻居数量被限制在 $\sqrt{N}$ 以内，所以单次操作开销不大。
    - 对重量团的操作，由于重量团的数量最多只有 $N/\sqrt{N} = \sqrt{N}$ 个，所以涉及重量团的计算总量也得到了控制。
    - 通过阈值 $\sqrt{N}$，我们在这两种开销之间取得了平衡。

*   **空间复杂度**: $O(N+M)$
    - 并查集、颜色、邻接表等基础数据结构占用了 $O(N+M)$ 的空间。
    - 分块的数据结构，无论是轻量团的邻居列表还是重量团的，其总条目数不会超过所有边的两倍，即 $O(M)$。所以总空间复杂度是 $O(N+M)$。

## 知识点总结

喵~ 这道题真是个很好的练习，我们从中可以学到很多东西呢！

1.  **并查集 (DSU)**: 解决连通性问题的强大工具，支持快速的合并与查询操作。
2.  **分块/重轻量思想 (Sqrt Decomposition)**: 当处理的对象有明显的“规模”差异时，这是一种非常有效的优化技巧。通过设定阈值，对不同规模的对象采用不同的处理策略，从而平衡整体复杂度。
3.  **启发式合并 (Union by Size/Rank)**: 在合并数据结构时（比如并查集、集合、邻接表），总是将小的合并到大的里面，可以有效降低均摊复杂度。
4.  **数据结构设计**: 针对特定问题设计高效的数据结构是算法竞赛的关键。本题中为重量团设计的“按颜色分类的邻居哈希表”就是一个很好的例子。
5.  **图论问题的转化**: 将“团”的概念转化为图论中的“同色连通块”，是解题的第一步。

希望这篇题解能帮到你，如果还有不明白的地方，随时可以再来问我哦！一起加油，喵~