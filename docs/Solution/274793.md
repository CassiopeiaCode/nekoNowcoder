# 骗子 - 题解

### 比赛与标签
> **比赛**: [牛客小白月赛95](https://ac.nowcoder.com/acm/contest/83236)

> **标签**: 树上问题, LCA, 01Trie, DSU on tree, 离线

> **难度**: \*3000

## 题目大意喵~

ฅ'ω'ฅ 各位旅行者，下午好呀！今天我们来解决一道关于在树上穿梭的有趣问题~

事情是这样的：我们有一棵 $n$ 个节点的树，每个节点 $i$ 都有一个权值 $a_i$。然后呢，会发生 $m$ 个事件，也就是 $m$ 次询问。

对于每一次询问，我们有一个初始的记忆值 $x$，然后要从一个节点 $u$ 出发，沿着树上唯一的简单路径走到另一个节点 $v$。在这个旅途中，记忆值会发生两种变化：
1.  每经过一条边，记忆值就会加 $1$。
2.  每到达一个节点（包括起点 $u$ 和终点 $v$），记忆值就会异或上该节点的权值 $a_i$。

我们的任务就是，对于每次询问，算出从 $u$ 走到 $v$ 之后，最终的记忆值是多少，喵~

举个栗子：比如我们从 $u$ 走到 $v$，路径是 $u \to p \to v$。
1.  初始记忆值为 `mem = x`。
2.  到达起点 $u$：`mem = mem ^ a_u`。
3.  走过边 $u \to p$：`mem = mem + 1`。
4.  到达节点 $p$：`mem = mem ^ a_p`。
5.  走过边 $p \to v$：`mem = mem + 1`。
6.  到达终点 $v$：`mem = mem ^ a_v`。

就是这样一个过程，我们需要算出最终的 `mem` 值。

## 解题思路分析

这道题的操作又是加法又是异或，这两种运算混在一起可是出了名的不好处理呢，喵~ 因为加法有进位，会影响到高位，而异或是按位独立的。直接模拟每一次询问的路径，对于 $m$ 次询问，每次最多走 $O(n)$ 的路程，总复杂度会是 $O(nm)$，肯定会超时的说。

### 拆解复杂的路径操作

既然是树上的路径问题，一个很自然的想法就是利用**最近公共祖先 (LCA)** 来拆解路径。从 $u$ 到 $v$ 的路径可以看作是从 $u$ 走到它们的LCA，我们叫它 $w$ 好了，然后再从 $w$ 走到 $v$。

路径 $u \to v$ = 路径 $u \to w$ + 路径 $w \to v$。

这样拆分后，我们就可以把一次询问 $(u, v, x)$ 的计算过程分成两部分：
1.  **上升阶段**：从 $u$ 走到 $w$。
2.  **下降阶段**：从 $w$ 走到 $v$。

但是，操作的顺序是固定的，我们不能简单地分开算然后合并。比如，从 $u$ 走到 $w$ 的结果，会作为从 $w$ 走到 $v$ 的初始值。这说明，我们需要一种方法来表示这一连串的 `(+1, ^a_i)` 操作。

### 神奇的01Trie来救场！

这种混合运算，特别是涉及到 `+1` 和 `^` 的，让我们想到了一个强大的数据结构——**01Trie**（字典树）！我们可以用01Trie来维护一个数字集合，并对集合中所有数字进行批量操作。

为了方便处理 `+1` 操作的进位，我们从**最低位到最高位 (LSB to MSB)** 来构建01Trie。

我们想在01Trie上实现两个核心的批量操作：
1.  **全体异或 `A`**：这个比较简单。要将所有数异或上 $A$，我们看 $A$ 的第 $k$ 位。如果为 $1$，就相当于在Trie的第 $k$ 层，所有节点的左儿子和右儿子交换。我们可以用一个**懒标记**来记录，查询时再把影响算上。
2.  **全体加 `1`**：这个是关键！
    - 考虑二进制加法，`val + 1` 会把 `val` 末尾连续的 `1` 都变成 `0`，然后把遇到的第一个 `0` 变成 `1`。
    - 在LSB优先的01Trie里，这意味着在第 $0$ 层（最低位），所有走向 `0` 孩子路径的数现在应该走向 `1`，反之亦然。所以我们交换第 $0$ 层的左右孩子。
    - 哪些数产生了进位呢？是那些第 $0$ 位是 `1` 的数。它们在交换后，都跑到了原来的 `0` 孩子那边。所以，我们只需要对现在的 `0` 孩子（也就是原来的 `1` 孩子）所代表的数，递归地进行 `+1` 操作（即在下一层处理进位）。

有了这两个操作，我们就可以把路径上的变换表示为对一个Trie的操作序列了！

### 离线处理与树上两趟DFS

询问是相互独立的，而且有很多，这提示我们可以**离线**处理。我们可以把所有询问拆分，挂在树的节点上，然后通过DFS遍历整棵树来一次性处理。

我们的策略是跑两趟DFS：

**第一趟DFS (`dfs1`)：自底向上，处理 $u \to \text{LCA}(u,v)$ 的上升部分**

- 我们从叶子节点开始，向上合并信息。每个节点 `curr` 维护一棵01Trie，`trie[curr]`，表示从 `curr` 子树中某些节点出发的路径，经过变换到达 `curr` 后的数值集合。
- `dfs1(curr, parent)` 的流程是：
    1.  递归调用 `dfs1` 处理 `curr` 的所有孩子。
    2.  对于每个孩子 `child`，它的Trie `trie[child]` 里的值，要走到 `curr`，需要经过 `child -> curr` 这条边，所以要对 `trie[child]` 全体 `+1`。
    3.  然后，把所有孩子处理后的Trie合并到 `trie[curr]` 中。这就是一种类似 **DSU on tree** 的思想。
    4.  处理所有以 `curr` 为**起点**的询问 $(u, v, x)$：将初始值 $x$ 插入到 `trie[curr]` 中。
    5.  到达节点 `curr` 会异或 `a_curr`，所以对 `trie[curr]` 全体异或 `a_curr`。
    6.  处理所有以 `curr` 为**LCA**的询问 $(u, v, x)$：此时，我们之前在 `u` 插入的 $x$ 已经经历了 $u \to curr$ 的所有变换，变成了中间值。我们查询这个值，并存起来，供第二趟DFS使用。

**第二趟DFS (`dfs2`)：自顶向下，处理 $\text{LCA}(u,v) \to v$ 的下降部分**

- 这次我们从根节点开始，维护一棵**全局的01Trie**。
- `dfs2(curr, parent)` 的流程是：
    1.  到达节点 `curr`，对全局Trie全体异或 `a_curr`。
    2.  处理所有以 `curr` 为**LCA**的询问：将在 `dfs1` 中算出的中间值插入到全局Trie中。
    3.  处理所有以 `curr` 为**终点**的询问：查询对应的值，这就是最终答案啦！
    4.  准备递归到孩子 `child`：要经过 `curr -> child` 这条边，所以对全局Trie全体 `+1`。
    5.  调用 `dfs2(child, curr)`。
    6.  从 `child` 回溯后，要撤销刚才的操作，以保证不影响 `curr` 的其他兄弟子树。所以对全局Trie全体 `-1`（`+1`的逆操作）。
    7.  在 `dfs2(curr, ...)` 返回前，也要撤销对 `a_curr` 的异或。

**一个小细节：Trie的合并**
在 `dfs1` 中，当我们将孩子的Trie合并到父亲时，为了高效地追踪每个询问插入的值在Trie中的位置（叶子节点），我们可以用一个并查集（DSU）来维护Trie节点的合并关系。这样，即使Trie的结构在合并中改变，我们也能通过 `find` 操作找到一个值对应的新叶子节点。

好啦，思路就是这样！有点复杂，但拆解开来看，每一步都是很清晰的，对吧？喵~ 接下来就让我们一起看看代码实现吧！

## 代码实现

```cpp
#include <iostream>
#include <vector>
#include <numeric>
#include <algorithm>
#include <cassert>

using namespace std;

using ll = long long;

const int MAXN = 300005;
const int LOGN = 20;
const int K = 40; // 位数，初始值和权值最大10^9约30位，加上路径长度，40位足够
const int MAX_TRIE_NODES = MAXN * (K + 5);

// --- 树和LCA ---
int n, m;
ll node_weights[MAXN];
vector<int> adj[MAXN];
int parent[MAXN][LOGN];
int depth[MAXN];

// --- 01 Trie ---
struct TrieNode {
    int children[2];
    ll lazy_xor_tag;
    int parent_ptr;
} trie_nodes[MAX_TRIE_NODES];
int trie_root[MAXN];
int trie_node_count;
int trie_dsu_parent[MAX_TRIE_NODES]; // DSU on trie nodes

// --- 离线查询 ---
struct Query {
    int id;
    ll initial_val;
};
vector<Query> queries_starting_at[MAXN];
vector<int> queries_lca_at[MAXN];
vector<int> queries_ending_at[MAXN];
ll query_answers[MAXN];
int query_trie_leaf_id[MAXN]; // 记录每个查询插入Trie后的叶子节点ID

// --- DSU on Trie Nodes ---
int find_trie_node(int i) {
    if (trie_dsu_parent[i] == i) return i;
    return trie_dsu_parent[i] = find_trie_node(trie_dsu_parent[i]);
}
void unite_trie_nodes(int i, int j) {
    int root_i = find_trie_node(i);
    int root_j = find_trie_node(j);
    if (root_i != root_j) {
        trie_dsu_parent[root_i] = root_j;
    }
}

// --- Trie 核心操作 ---
int create_node() {
    ++trie_node_count;
    trie_nodes[trie_node_count].children[0] = trie_nodes[trie_node_count].children[1] = 0;
    trie_nodes[trie_node_count].lazy_xor_tag = 0;
    trie_nodes[trie_node_count].parent_ptr = 0;
    trie_dsu_parent[trie_node_count] = trie_node_count;
    return trie_node_count;
}

void push_down(int u) {
    if (trie_nodes[u].lazy_xor_tag == 0) return;
    ll tag = trie_nodes[u].lazy_xor_tag;
    for (int i = 0; i < 2; ++i) {
        if (trie_nodes[u].children[i]) {
            trie_nodes[trie_nodes[u].children[i]].lazy_xor_tag ^= tag;
        }
    }
    trie_nodes[u].lazy_xor_tag = 0;
}

int insert_val(int& root, ll val) {
    if (!root) root = create_node();
    int curr = root;
    for (int i = 0; i < K; ++i) {
        push_down(curr);
        val ^= trie_nodes[curr].lazy_xor_tag;
        int bit = (val >> i) & 1;
        if (!trie_nodes[curr].children[bit]) {
            trie_nodes[curr].children[bit] = create_node();
            trie_nodes[trie_nodes[curr].children[bit]].parent_ptr = curr;
        }
        curr = trie_nodes[curr].children[bit];
    }
    return curr;
}

ll query_val(int leaf_id) {
    ll val = 0;
    int curr = leaf_id;
    for (int i = K - 1; i >= 0; --i) {
        int p = trie_nodes[curr].parent_ptr;
        val ^= trie_nodes[p].lazy_xor_tag;
        if (trie_nodes[p].children[1] == curr) {
            val |= (1LL << i);
        }
        curr = p;
    }
    val ^= trie_nodes[curr].lazy_xor_tag; // Don't forget the root's tag
    return val;
}

void apply_add_one(int u, int k) {
    if (!u || k >= K) return;
    push_down(u);
    swap(trie_nodes[u].children[0], trie_nodes[u].children[1]);
    apply_add_one(trie_nodes[u].children[0], k + 1); // Carry propagates
}

void apply_sub_one(int u, int k) {
    if (!u || k >= K) return;
    push_down(u);
    swap(trie_nodes[u].children[0], trie_nodes[u].children[1]);
    apply_sub_one(trie_nodes[u].children[1], k + 1); // Borrow propagates
}

int merge_tries(int u, int v, ll lazy_w, int k) {
    if (!u) {
        if (v) trie_nodes[v].lazy_xor_tag ^= lazy_w;
        return v;
    }
    if (!v) return u;

    if (k == K) { // Reached leaf level
        unite_trie_nodes(u, v);
        return u;
    }

    push_down(u);
    push_down(v);
    lazy_w ^= trie_nodes[u].lazy_xor_tag ^ trie_nodes[v].lazy_xor_tag;
    
    for(int i = 0; i < 2; ++i) {
        int bit_v = ((lazy_w >> k) & 1) ^ i;
        trie_nodes[u].children[i] = merge_tries(trie_nodes[u].children[i], trie_nodes[v].children[bit_v], lazy_w, k + 1);
        if (trie_nodes[u].children[i]) {
            trie_nodes[trie_nodes[u].children[i]].parent_ptr = u;
        }
    }
    return u;
}

// --- LCA and DFS traversals ---
void lca_dfs(int u, int p, int d) {
    depth[u] = d;
    parent[u][0] = p;
    for (int v : adj[u]) {
        if (v != p) {
            lca_dfs(v, u, d + 1);
        }
    }
}

void lca_init() {
    lca_dfs(1, 0, 0);
    for (int j = 1; j < LOGN; ++j) {
        for (int i = 1; i <= n; ++i) {
            if (parent[i][j - 1] != 0) {
                parent[i][j] = parent[parent[i][j - 1]][j - 1];
            }
        }
    }
}

int get_lca(int u, int v) {
    if (depth[u] < depth[v]) swap(u, v);
    for (int j = LOGN - 1; j >= 0; --j) {
        if (depth[u] - (1 << j) >= depth[v]) {
            u = parent[u][j];
        }
    }
    if (u == v) return u;
    for (int j = LOGN - 1; j >= 0; --j) {
        if (parent[u][j] != 0 && parent[u][j] != parent[v][j]) {
            u = parent[u][j];
            v = parent[v][j];
        }
    }
    return parent[u][0];
}

void dfs1(int u, int p) {
    trie_root[u] = 0;
    for (int v : adj[u]) {
        if (v == p) continue;
        dfs1(v, u);
        apply_add_one(trie_root[v], 0); // Edge v->u adds 1
        trie_root[u] = merge_tries(trie_root[u], trie_root[v], 0, 0);
    }

    for (const auto& q : queries_starting_at[u]) {
        query_trie_leaf_id[q.id] = insert_val(trie_root[u], q.initial_val);
    }
    
    if (trie_root[u]) {
        trie_nodes[trie_root[u]].lazy_xor_tag ^= node_weights[u];
    }
    
    for (int q_id : queries_lca_at[u]) {
        int leaf_id = find_trie_node(query_trie_leaf_id[q_id]);
        query_answers[q_id] = query_val(leaf_id);
    }
}

void dfs2(int u, int p, int& global_trie_root) {
    if (global_trie_root) {
        trie_nodes[global_trie_root].lazy_xor_tag ^= node_weights[u];
    }

    for (int q_id : queries_lca_at[u]) {
        query_trie_leaf_id[q_id] = insert_val(global_trie_root, query_answers[q_id]);
    }
    
    for (int q_id : queries_ending_at[u]) {
        int leaf_id = find_trie_node(query_trie_leaf_id[q_id]);
        query_answers[q_id] = query_val(leaf_id);
    }

    for (int v : adj[u]) {
        if (v == p) continue;
        apply_add_one(global_trie_root, 0);
        dfs2(v, u, global_trie_root);
        apply_sub_one(global_trie_root, 0); // Backtrack
    }
    
    if (global_trie_root) {
        trie_nodes[global_trie_root].lazy_xor_tag ^= node_weights[u]; // Backtrack
    }
}


int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(nullptr);

    cin >> n >> m;
    for (int i = 1; i <= n; ++i) cin >> node_weights[i];
    for (int i = 0; i < n - 1; ++i) {
        int u, v;
        cin >> u >> v;
        adj[u].push_back(v);
        adj[v].push_back(u);
    }

    lca_init();

    for (int i = 1; i <= m; ++i) {
        ll x;
        int u, v;
        cin >> x >> u >> v;
        int w = get_lca(u, v);
        queries_starting_at[u].push_back({i, x});
        queries_lca_at[w].push_back(i);
        queries_ending_at[v].push_back(i);
    }

    dfs1(1, 0);
    
    // Reset for second DFS
    trie_node_count = 0;
    int global_trie_root = 0;

    dfs2(1, 0, global_trie_root);

    for (int i = 1; i <= m; ++i) {
        cout << query_answers[i] << "\n";
    }

    return 0;
}
```

## 复杂度分析

- **时间复杂度**: $O(N \log N + M (\log N + K))$
    - **LCA预处理**: `lca_dfs`是 $O(N)$，`lca_init`的二分倍增表是 $O(N \log N)$。
    - **查询LCA**: 每次查询是 $O(\log N)$。
    - **DFS1**: 每个节点访问一次。在每个节点，Trie的合并操作是主要的开销。启发式合并（DSU on tree）的思想保证了每个Trie节点只会被合并 $O(\log N)$ 次。每个Trie操作（插入、查询、加一）的深度是 $K$。所以这部分总共是 $O(N \cdot K \cdot \log N)$。加上处理询问的开销是 $O(M \cdot K)$。
    - **DFS2**: 每个节点访问一次。Trie的操作是 $O(K)$。总共是 $O(N \cdot K + M \cdot K)$。
    - 综合起来，主要瓶颈在于Trie的操作和LCA。总时间复杂度近似为 $O((N+M)K + (N+M)\log N)$。其中 $K$ 是我们选择的位数，是一个常数。

- **空间复杂度**: $O(N \log N + M + NK)$
    - **树和LCA**: 邻接表 $O(N)$，LCA的`parent`数组 $O(N \log N)$。
    - **查询**: 存储查询信息的数组是 $O(M)$。
    - **01Trie**: 这是空间的大头。在 `dfs1 中，最坏情况下所有节点都不合并，每个节点插入一个值，总节点数可能是 $O(N \cdot K)$。在 dfs2` 中是 $O(M \cdot K)$。所以Trie的空间是 $O((N+M)K)$。

## 知识点总结

这道题是多种算法和数据结构的绝妙组合，真是让人大开眼界呢，喵！

1.  **LCA (最近公共祖先)**: 解决树上路径问题的基本工具，通过二分倍增法可以高效求解。
2.  **离线处理**: 当询问可以不按顺序回答时，离线处理所有询问，然后通过一次或多次遍历来统一计算，是处理复杂数据结构问题的常用技巧。
3.  **01Trie**: 处理异或问题的利器。这道题展示了它更强大的能力，通过巧妙的设计（从LSB到MSB建树），还能高效处理 `+1` 这样的算术运算。
4.  **Trie上的懒标记**: 对于区间修改（这里是全体修改），懒标记是降低复杂度的关键。
5.  **DSU on Tree (树上启发式合并)**: `dfs1`中合并Trie的思想，虽然没有显式地按子树大小合并，但自底向上的合并过程本质上就是启发式合并，保证了总的合并代价。
6.  **两遍扫描/DFS**: 先自底向上收集信息，再自顶向下分发/计算结果，是处理树上依赖路径信息的经典模式。

总而言之，这是一道非常好的练习题，能够加深对树上问题、数据结构组合以及离线算法思想的理解。能解出这道题的旅行者，一定是非常厉害的算法大师了，喵~ (ฅ́˘ฅ̀)♡